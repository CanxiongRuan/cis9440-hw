{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWFa-5lpOALy",
    "outputId": "1991f1d5-d262-41ca-aac7-6b48328a32e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage-blob\n",
      "  Downloading azure_storage_blob-12.19.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.5/394.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob)\n",
      "  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (42.0.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.10.0)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2024.2.2)\n",
      "Installing collected packages: isodate, azure-core, azure-storage-blob\n",
      "Successfully installed azure-core-1.30.1 azure-storage-blob-12.19.1 isodate-0.6.1\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.72-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting botocore<1.35.0,>=1.34.72 (from boto3)\n",
      "  Downloading botocore-1.34.72-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.72->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.72->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.72->boto3) (1.16.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.34.72 botocore-1.34.72 jmespath-1.0.1 s3transfer-0.10.1\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.11.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.63.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.2.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-storage-blob\n",
    "!pip install boto3\n",
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dnxRJJhJGrGU"
   },
   "outputs": [],
   "source": [
    "# import Librairies\n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from google.cloud import storage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bLW_UOQsCRhT"
   },
   "outputs": [],
   "source": [
    "# Function\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "# Azure Functions\n",
    "def azure_upload_blob(connect_str, container_name, blob_name, data):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    blob_client.upload_blob(data, overwrite=True)\n",
    "    print(f\"Uploaded to Azure Blob: {blob_name}\")\n",
    "\n",
    "def azure_download_blob(connect_str, container_name, blob_name):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    download_stream = blob_client.download_blob()\n",
    "    return download_stream.readall()\n",
    "\n",
    "# Google Cloud Functions\n",
    "def google_upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n",
    "\n",
    "def google_download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "    print(f\"Blob {source_blob_name} downloaded to {destination_file_name}.\")\n",
    "\n",
    "# AWS Functions\n",
    "def aws_upload_file(file_name, bucket, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    print(f\"Uploaded {file_name} to S3 bucket {bucket}.\")\n",
    "\n",
    "def aws_download_file(bucket, object_name, file_name):\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_client.download_file(bucket, object_name, file_name)\n",
    "    print(f\"Downloaded {object_name} from S3 bucket {bucket}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utM-jIdhJZeG"
   },
   "source": [
    "s1 --> Gather --> Deccompress --> Convert to Tabular --> Clean  --> Reformat ---> Consolidation --> Transformation --> Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LuaD8dc4Iia_",
    "outputId": "2d079da1-09e2-4409-b3f9-fd5523f2682a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime',\n",
      "       'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID',\n",
      "       'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax',\n",
      "       'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge',\n",
      "       'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2024-01.parquet\"\n",
    "\n",
    "df_raw = pd.read_parquet(URL, engine = 'pyarrow')\n",
    "df_raw.head()\n",
    "print(df_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wx6qd381LPOw",
    "outputId": "555af3be-d6df-4e6c-dd48-82ac53d47f7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56551, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HbVgHulLdGi",
    "outputId": "f4b4b814-adf8-4c5c-9059-276577aa3b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56551 entries, 0 to 56550\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               56551 non-null  int32         \n",
      " 1   lpep_pickup_datetime   56551 non-null  datetime64[ns]\n",
      " 2   lpep_dropoff_datetime  56551 non-null  datetime64[ns]\n",
      " 3   store_and_fwd_flag     53136 non-null  object        \n",
      " 4   RatecodeID             53136 non-null  float64       \n",
      " 5   PULocationID           56551 non-null  int32         \n",
      " 6   DOLocationID           56551 non-null  int32         \n",
      " 7   passenger_count        53136 non-null  float64       \n",
      " 8   trip_distance          56551 non-null  float64       \n",
      " 9   fare_amount            56551 non-null  float64       \n",
      " 10  extra                  56551 non-null  float64       \n",
      " 11  mta_tax                56551 non-null  float64       \n",
      " 12  tip_amount             56551 non-null  float64       \n",
      " 13  tolls_amount           56551 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  56551 non-null  float64       \n",
      " 16  total_amount           56551 non-null  float64       \n",
      " 17  payment_type           53136 non-null  float64       \n",
      " 18  trip_type              53133 non-null  float64       \n",
      " 19  congestion_surcharge   53136 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(14), int32(3), object(1)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbjmBtfWLukZ"
   },
   "outputs": [],
   "source": [
    "df_cleaned = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luizwkAGL1OL",
    "outputId": "67b336f2-0ea0-45e1-830d-1d24a620b7fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56551 entries, 0 to 56550\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               56551 non-null  int32         \n",
      " 1   lpep_pickup_datetime   56551 non-null  datetime64[ns]\n",
      " 2   lpep_dropoff_datetime  56551 non-null  datetime64[ns]\n",
      " 3   store_and_fwd_flag     53136 non-null  object        \n",
      " 4   RatecodeID             53136 non-null  float64       \n",
      " 5   PULocationID           56551 non-null  int32         \n",
      " 6   DOLocationID           56551 non-null  int32         \n",
      " 7   passenger_count        53136 non-null  float64       \n",
      " 8   trip_distance          56551 non-null  float64       \n",
      " 9   fare_amount            56551 non-null  float64       \n",
      " 10  extra                  56551 non-null  float64       \n",
      " 11  mta_tax                56551 non-null  float64       \n",
      " 12  tip_amount             56551 non-null  float64       \n",
      " 13  tolls_amount           56551 non-null  float64       \n",
      " 14  improvement_surcharge  56551 non-null  float64       \n",
      " 15  total_amount           56551 non-null  float64       \n",
      " 16  payment_type           53136 non-null  float64       \n",
      " 17  trip_type              53133 non-null  float64       \n",
      " 18  congestion_surcharge   53136 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(13), int32(3), object(1)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = df_raw.drop(columns=  ['ehail_fee'])\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bymRzdQ1NXVG",
    "outputId": "29abf81b-4831-4ab0-ef34-32f0b1778b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded greentaxi.csv to Azure Blob Storage in container greentaxi.\n"
     ]
    }
   ],
   "source": [
    "CONNECTION_STRING_AZURE_STORAGE = \"DefaultEndpointsProtocol=https;AccountName=stgreentaxicis9440;AccountKey=ajPKTHo7EI1ANhNdjqsmd5PQD/n/1KhAGjGKCgn5zRUg1s39N0yzNFGf9SwUHpGdtV3GSREl8qSc+AStI/9U2w==;EndpointSuffix=core.windows.net\"\n",
    "CONTAINER_AZURE = 'greentaxi'\n",
    "blob_name = \"greentaxi.csv\"\n",
    "# Convert DataFrame to CSV\n",
    "output = StringIO()\n",
    "df_raw.to_csv(output, index=False)\n",
    "data = output.getvalue()\n",
    "output.close()\n",
    "\n",
    "# Create the BlobServiceClient object\n",
    "blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING_AZURE_STORAGE)\n",
    "\n",
    "# Get a blob client using the container name and blob name\n",
    "blob_client = blob_service_client.get_blob_client(container=CONTAINER_AZURE, blob=blob_name)\n",
    "\n",
    "# Upload the CSV data\n",
    "blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "print(f\"Uploaded {blob_name} to Azure Blob Storage in container {CONTAINER_AZURE}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "lJJiIYvKCaiE",
    "outputId": "251d1dd1-f437-432f-8c23-67b9f8173091"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azure_upload_blob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-220a10eda914>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mazure_blob_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'your_blob_name.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mazure_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Hello, Azure!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mazure_upload_blob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mazure_connect_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazure_container_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazure_blob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazure_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Download and print the blob content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mazure_blob_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mazure_download_blob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mazure_connect_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazure_container_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazure_blob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'azure_upload_blob' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    output = StringIO()\n",
    "    df_raw.to_csv(output, index=False)\n",
    "    data = output.getvalue()\n",
    "    output.close()\n",
    "\n",
    "    # Azure\n",
    "    azure_connect_str = 'YOUR_AZURE_STORAGE_CONNECTION_STRING'\n",
    "    azure_container_name = 'YOUR_CONTAINER_NAME'\n",
    "    azure_blob_name = 'your_blob_name.csv'\n",
    "    azure_data = 'Hello, Azure!'\n",
    "    azure_upload_blob(azure_connect_str, azure_container_name, azure_blob_name, azure_data)\n",
    "    # Download and print the blob content\n",
    "    azure_blob_content = azure_download_blob(azure_connect_str, azure_container_name, azure_blob_name)\n",
    "    print(azure_blob_content)\n",
    "\n",
    "    # Google Cloud\n",
    "    google_bucket_name = 'YOUR_BUCKET_NAME'\n",
    "    google_source_file_name = 'local_file_to_upload.txt'\n",
    "    google_destination_blob_name = 'your_blob_name_in_google_storage.txt'\n",
    "    google_download_destination = 'downloaded_file_name.txt'\n",
    "    google_upload_blob(google_bucket_name, google_source_file_name, google_destination_blob_name)\n",
    "    google_download_blob(google_bucket_name, google_destination_blob_name, google_download_destination)\n",
    "\n",
    "    # AWS S3\n",
    "    aws_bucket_name = 'YOUR_BUCKET_NAME'\n",
    "    aws_file_name = 'local_file_to_upload.txt'\n",
    "    aws_object_name = 'your_object_name_in_s3.txt'\n",
    "    aws_download_destination = 'downloaded_aws_file.txt'\n",
    "    aws_upload_file(aws_file_name, aws_bucket_name, aws_object_name)\n",
    "    aws_download_file(aws_bucket_name, aws_object_name, aws_download_destination)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
